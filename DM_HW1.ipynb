{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, nltk, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpaper = 'paper_dataset.txt'\n",
    "fref = 'paper_reference_index.txt'\n",
    "flink = 'paper_reference_links.txt'\n",
    "dpaper = pd.read_csv(fpaper, sep='\\t')\n",
    "dref = pd.read_csv(fref, sep='\\t')\n",
    "dlink = pd.read_csv(flink, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequent author sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_authors = np.array(dpaper['authors'])\n",
    "# arr_authors_all = np.append(np.array(dpaper['authors']), np.array(dref['authors']))\n",
    "\n",
    "authors_list=[]\n",
    "for i in range(arr_authors.size):\n",
    "    authors_list.append(arr_authors[i].split(\" + \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge same authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_authors = []\n",
    "for authors_of_a_paper in authors_list:\n",
    "    for single_author in authors_of_a_paper:\n",
    "        all_authors.append(single_author)\n",
    "all_authors.sort()\n",
    "\n",
    "\n",
    "for index1, authors_of_a_paper in enumerate(authors_list):\n",
    "    for index2, single_author in enumerate(authors_of_a_paper):\n",
    "        if single_author == 'scholkopf':\n",
    "            authors_list[index1][index2] = 'bernhard scholkopf'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oht = OnehotTransactions()\n",
    "oht_ary = oht.fit(authors_list).transform(authors_list)\n",
    "df = pd.DataFrame(oht_ary, columns=oht.columns_)\n",
    "\n",
    "frequent_author_sets=apriori(df, min_support=0.002, use_colnames=True)\n",
    "sorted_frequent_sets = frequent_author_sets.sort_values('support', ascending=False)\n",
    "\n",
    "author_rules=association_rules(sorted_frequent_sets, metric=\"confidence\", min_threshold=0.6)\n",
    "sorted_author_rules = author_rules.sort_values(['support','lift','confidence'], ascending=[False, False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequent paper sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_source = np.array(dlink['source'])\n",
    "arr_ref = np.array(dlink['target'])\n",
    "\n",
    "ref_list = []\n",
    "i = 0\n",
    "j = 0\n",
    "ref_list.append([])\n",
    "for index, source in enumerate(arr_source):\n",
    "    if(arr_source[index] == arr_source[i]):\n",
    "        ref_list[j].append(arr_ref[index])\n",
    "    else:\n",
    "        i = index\n",
    "        j = j + 1\n",
    "        ref_list.append([])\n",
    "        ref_list[j].append(arr_ref[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oht1 = OnehotTransactions()\n",
    "oht_ary1 = oht1.fit(ref_list).transform(ref_list)\n",
    "df1 = pd.DataFrame(oht_ary1, columns=oht1.columns_)\n",
    "\n",
    "frequent_ref_sets=apriori(df1, min_support=0.01, use_colnames=True)\n",
    "\n",
    "sorted_frequent_ref_sets = frequent_ref_sets.sort_values('support', ascending=False)\n",
    "\n",
    "ref_rules=association_rules(sorted_frequent_ref_sets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "sorted_ref_rules = ref_rules.sort_values(['lift','support','confidence'], ascending=[False, False, False])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
